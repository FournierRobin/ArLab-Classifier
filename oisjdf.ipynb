{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "from clearml import Task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-03 15:55:35,524 - clearml.util - WARNING - 6 task found when searching for `{'project_name': 'ArLab Classifier', 'task_name': '2 : Preprocess dataset 03-05', 'include_archived': True}`\n",
      "2023-05-03 15:55:35,524 - clearml.util - WARNING - Selected task `2 : Preprocess dataset 03-05` (id=c289e64c1a7b47cd807ebf6b032a0f29)\n",
      "dict_keys(['X_test', 'X_train', 'vectorizer', 'y_test', 'y_train'])\n"
     ]
    }
   ],
   "source": [
    "os.environ['CLEARML_API_HOST'] = \"https://api.clear.ml\"\n",
    "os.environ['CLEARML_WEB_HOST'] = \"https://app.clear.ml\"\n",
    "os.environ['CLEARML_FILES_HOST'] = \"https://files.clear.ml\"\n",
    "os.environ['CLEARML_API_ACCESS_KEY'] = \"NXRS736MXOJ50V3NIZD5\"\n",
    "os.environ['CLEARML_API_SECRET_KEY'] = \"ibFYNMzbUiVb8VpRZOZducTBVRUHfpDMWLe4AQE2C4vrsnl4JU\"\n",
    "\n",
    "current_date = dt.datetime.now().strftime('%d-%m')\n",
    "#task = Task.init(project_name=\"ArLab Classifier\", task_name=f\"3 : Train model {current_date}\")\n",
    "\n",
    "dataset_task = Task.get_task(project_name=\"ArLab Classifier\", task_name=f\"2 : Preprocess dataset {current_date}\")\n",
    "print(dataset_task.artifacts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://files.clear.ml/ArLab%20Classifier/2%20%253A%20Preprocess%20dataset%2003-05.8ea36bd96b3546f991a879c9134ee82f/artifacts/y_test/y_test.pkl\n",
    "https://files.clear.ml/ArLab%20Classifier/2%20%253A%20Preprocess%20dataset%2003-05.8ea36bd96b3546f991a879c9134ee82f/artifacts/y_test/y_test.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robinfournier/Desktop/arlab/arlabenv/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MultinomialNB from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/robinfournier/Desktop/arlab/arlabenv/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator CountVectorizer from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define input and output data types\n",
    "class InputData(BaseModel):\n",
    "    text: str\n",
    "\n",
    "class OutputData(BaseModel):\n",
    "    label: str\n",
    "    confidence: float\n",
    "\n",
    "def predict(input_data: InputData):\n",
    "    # Process the input data\n",
    "    text = input_data.text\n",
    "    X = vectorizer.transform([text])\n",
    "\n",
    "    # Pass the data through your model to get the prediction\n",
    "    pred = model.predict(X)\n",
    "    proba = model.predict_proba(X)[0][pred]\n",
    "\n",
    "    # Return the prediction as output data\n",
    "    return {\"label\": pred[0], \"confidence\": proba}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robinfournier/Desktop/arlab/arlabenv/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MultinomialNB from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/robinfournier/Desktop/arlab/arlabenv/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator CountVectorizer from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = joblib.load(\"models/nb_03-05.pkl\")\n",
    "vectorizer = joblib.load(\"models/vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"i don't know\"\n",
    "X = vectorizer.transform([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, 'x'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmodels/nb_03-05.pkl\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m----> 3\u001b[0m     nb_model, vectorizer \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(f)\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, 'x'."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api:\n",
    "    build:\n",
    "      context: ./api\n",
    "      dockerfile: ./Dockerfile\n",
    "    environment:\n",
    "      <<: *airflow-common-env\n",
    "    ports:\n",
    "      - \"8000:8000\"\n",
    "    volumes:\n",
    "      - ./models:/app/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'datasets/full_articles_{current_date}.csv')\n",
    "\n",
    "df = df.dropna()\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['article_text'], df['label'], test_size=0.2, random_state=42)\n",
    "vectorizer = CountVectorizer(stop_words=custom_stopwords_fr())\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arlabenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
